{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b35f8e80-5fef-494f-9797-fbd9c8600808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (3.14.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from SpeechRecognition) (4.11.0)\n",
      "Requirement already satisfied: pyaudio in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (0.2.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition\n",
    "!pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4974433-2c80-4cdd-8564-6bf8bf005b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (3.14.1)\n",
      "Requirement already satisfied: openai-whisper in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (20240930)\n",
      "Requirement already satisfied: pydub in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: noisereduce in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from SpeechRecognition) (4.11.0)\n",
      "Requirement already satisfied: numba in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from openai-whisper) (0.60.0)\n",
      "Requirement already satisfied: torch in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from openai-whisper) (2.6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from openai-whisper) (4.66.5)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from openai-whisper) (10.3.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from openai-whisper) (0.9.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from noisereduce) (1.13.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from noisereduce) (3.9.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from noisereduce) (1.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib->noisereduce) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib->noisereduce) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib->noisereduce) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib->noisereduce) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib->noisereduce) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib->noisereduce) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib->noisereduce) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib->noisereduce) (2.9.0.post0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from numba->openai-whisper) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (3.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm->openai-whisper) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2->torch->openai-whisper) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition openai-whisper pydub numpy noisereduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e849cfb-de18-488a-b584-78fe18e339f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-whisper in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (20240930)\n",
      "Requirement already satisfied: numba in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from openai-whisper) (0.60.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from openai-whisper) (1.26.4)\n",
      "Requirement already satisfied: torch in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from openai-whisper) (2.6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from openai-whisper) (4.66.5)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from openai-whisper) (10.3.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from openai-whisper) (0.9.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from numba->openai-whisper) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm->openai-whisper) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2->torch->openai-whisper) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e169bd4-b658-4b0e-b5c8-ede8cb6261ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio[ffmpeg] in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (2.33.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from imageio[ffmpeg]) (1.26.4)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from imageio[ffmpeg]) (10.4.0)\n",
      "Requirement already satisfied: imageio-ffmpeg in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from imageio[ffmpeg]) (0.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from imageio[ffmpeg]) (5.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imageio[ffmpeg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "def7467a-c80b-4ffa-9424-4192071bfcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (4.49.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: torch==2.6.0 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from torchaudio) (2.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.6.0->torchaudio) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.6.0->torchaudio) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.6.0->torchaudio) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.6.0->torchaudio) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.6.0->torchaudio) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.6.0->torchaudio) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch==2.6.0->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2->torch==2.6.0->torchaudio) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a9efd7e-7e83-4f91-b837-961aa70b9395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pocketsphinx in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (5.0.4)\n",
      "Requirement already satisfied: sounddevice in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from pocketsphinx) (0.5.1)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from sounddevice->pocketsphinx) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\922991339\\appdata\\local\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice->pocketsphinx) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install pocketsphinx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a6d83f4-960c-447d-a3dd-764114d9fa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio file found. Processing...\n",
      "Audio converted successfully!\n",
      "Noise reduction applied!\n",
      "Google Speech Recognition Output:\n",
      " many animals of even complex structure which live parasitically within others are wholly devoid of an alimentary cavity\n",
      "Running Whisper Model...\n",
      "OpenAI Whisper Output:\n",
      "  Many animals of even complex structure which live parasitically within others are wholly devoid of an elementary cavity.\n",
      "Speech recognition complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import speech_recognition as sr\n",
    "import whisper\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import noisereduce as nr\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Ensure Audio File Exists\n",
    "audio_path = \"audio.wav\"  # Change this to your actual file\n",
    "if not os.path.exists(audio_path):\n",
    "    raise FileNotFoundError(f\" Audio file '{audio_path}' not found!\")\n",
    "\n",
    "print(\"Audio file found. Processing...\")\n",
    "\n",
    "# Convert Audio to Correct Format (Mono, 16-bit, 16kHz WAV)\n",
    "converted_audio_path = \"converted_audio.wav\"\n",
    "audio = AudioSegment.from_file(audio_path)\n",
    "audio = audio.set_channels(1).set_frame_rate(16000).set_sample_width(2)\n",
    "audio.export(converted_audio_path, format=\"wav\")\n",
    "print(\"Audio converted successfully!\")\n",
    "\n",
    "# Reduce Noise\n",
    "rate, data = wav.read(converted_audio_path)\n",
    "data = data.astype(np.float32)  # Ensure correct data type\n",
    "reduced_noise = nr.reduce_noise(y=data, sr=rate)\n",
    "\n",
    "# Save Cleaned Audio\n",
    "cleaned_audio_path = \"cleaned_audio.wav\"\n",
    "wav.write(cleaned_audio_path, rate, reduced_noise.astype(np.int16))  # Convert back to int16\n",
    "print(\"Noise reduction applied!\")\n",
    "\n",
    "# Initialize Recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Load Cleaned Audio for Speech Recognition\n",
    "with sr.AudioFile(cleaned_audio_path) as source:\n",
    "    audio = recognizer.record(source)\n",
    "\n",
    "# Recognize Speech using Google API\n",
    "try:\n",
    "    google_text = recognizer.recognize_google(audio)\n",
    "    print(\"Google Speech Recognition Output:\\n\", google_text)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand the audio.\")\n",
    "except sr.RequestError:\n",
    "    print(\"Google API request failed.\")\n",
    "\n",
    "# Recognize Speech using OpenAI Whisper\n",
    "print(\"Running Whisper Model...\")\n",
    "whisper_model = whisper.load_model(\"base\")\n",
    "\n",
    "# Run Whisper with CPU Mode (Fixes FP16 Error)\n",
    "whisper_text = whisper_model.transcribe(cleaned_audio_path, fp16=False)[\"text\"]\n",
    "\n",
    "print(\"OpenAI Whisper Output:\\n\", whisper_text)\n",
    "print(\"Speech recognition complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df45b96-f462-489b-932f-97462c8fb26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extracting first 5 seconds of audio...\n",
      "Short segment saved as 'short_audio.wav'.\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "# Ensure 'cleaned_audio.wav' exists before processing\n",
    "cleaned_audio_path = \"cleaned_audio.wav\"\n",
    "short_audio_path = \"short_audio.wav\"\n",
    "\n",
    "if not os.path.exists(cleaned_audio_path):\n",
    "    raise FileNotFoundError(f\" File '{cleaned_audio_path}' not found! Ensure it was created properly.\")\n",
    "\n",
    "print(\" Extracting first 5 seconds of audio...\")\n",
    "\n",
    "# Load the existing cleaned audio and extract the first 5 seconds\n",
    "audio = AudioSegment.from_wav(cleaned_audio_path)\n",
    "segment = audio[:5000]  # Extract first 5 seconds\n",
    "\n",
    "# Export the extracted segment\n",
    "segment.export(short_audio_path, format=\"wav\")\n",
    "print(\"Short segment saved as 'short_audio.wav'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b43e4b51-e296-46cc-b4ac-11f3738725e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Speech Recognition (First 5 Secs):\n",
      " many animals of even complex structure which live parasitically within other\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# Initialize recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Transcribe the extracted segment using Google Speech Recognition\n",
    "with sr.AudioFile(short_audio_path) as source:\n",
    "    short_audio = recognizer.record(source)\n",
    "\n",
    "try:\n",
    "    segment_text_google = recognizer.recognize_google(short_audio)\n",
    "    print(\"Google Speech Recognition (First 5 Secs):\\n\", segment_text_google)\n",
    "except sr.UnknownValueError:\n",
    "    segment_text_google = \"N/A\"\n",
    "    print(\"Google Speech API could not understand the short segment.\")\n",
    "except sr.RequestError:\n",
    "    segment_text_google = \"N/A\"\n",
    "    print(\" Google Speech API request failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "727b1c8d-d718-4b49-b96a-fbcd937d75a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Whisper on short segment...\n",
      "OpenAI Whisper (First 5 Secs):\n",
      "  many animals of even complex structure which live parasitically within others.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "# Run Whisper on the short segment\n",
    "print(\"Running Whisper on short segment...\")\n",
    "whisper_model = whisper.load_model(\"base\")\n",
    "\n",
    "# Run Whisper directly on `short_audio.wav`\n",
    "whisper_text_segment = whisper_model.transcribe(short_audio_path, fp16=False)[\"text\"]\n",
    "print(\"OpenAI Whisper (First 5 Secs):\\n\", whisper_text_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3e502fc-e485-4587-bffe-ff9b46f37028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç ASR Model Benchmarking:\n",
      "Google Speech Recognition Output:\n",
      "many animals of even complex structure which live parasitically within other\n",
      "OpenAI Whisper Output:\n",
      " many animals of even complex structure which live parasitically within others.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç ASR Model Benchmarking:\")\n",
    "print(f\"Google Speech Recognition Output:\\n{segment_text_google}\")\n",
    "print(f\"OpenAI Whisper Output:\\n{whisper_text_segment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "934dc92f-eda5-499b-9c1e-4b96e7042455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keywords Found in Speech:\n",
      "   - Animals\n",
      "   - complex\n",
      "   - parasitically\n",
      "ASRcomparison & keyword extraction completed!\n"
     ]
    }
   ],
   "source": [
    "# Identify Keywords in the Transcription\n",
    "keywords = [\"Animals\", \"complex\", \"parasitically\"]  # Customize keywords\n",
    "\n",
    "found_keywords = [word for word in keywords if word.lower() in whisper_text_segment.lower()]\n",
    "\n",
    "if found_keywords:\n",
    "    print(\"\\nKeywords Found in Speech:\")\n",
    "    for word in found_keywords:\n",
    "        print(f\"   - {word}\")\n",
    "else:\n",
    "    print(\"\\nNo target keywords found in speech.\")\n",
    "\n",
    "print(\"ASRcomparison & keyword extraction completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8742d549-393a-4877-9883-36a434c2c690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f4f69af-361e-4084-9aff-bce1637ccda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Google Speech Recognition Output:\n",
      " many animals of even complex structure which live parasitically within other\n",
      " CMU Sphinx Speech Recognition Output:\n",
      " any animals a huge complex structure which would heart sick we begin on\n",
      " Running Whisper on short segment...\n",
      " OpenAI Whisper Output:\n",
      "  many animals of even complex structure which live parasitically within others.\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import whisper\n",
    "\n",
    "# Initialize recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Load Short Audio for Processing\n",
    "with sr.AudioFile(\"short_audio.wav\") as source:\n",
    "    short_audio = recognizer.record(source)\n",
    "\n",
    "# **Google Speech API**\n",
    "try:\n",
    "    google_text = recognizer.recognize_google(short_audio)\n",
    "    print(\" Google Speech Recognition Output:\\n\", google_text)\n",
    "except sr.UnknownValueError:\n",
    "    google_text = \"N/A\"\n",
    "    print(\" Google Speech API could not understand the short segment.\")\n",
    "except sr.RequestError:\n",
    "    google_text = \"N/A\"\n",
    "    print(\" Google Speech API request failed.\")\n",
    "\n",
    "# **CMU Sphinx (Offline ASR)**\n",
    "try:\n",
    "    sphinx_text = recognizer.recognize_sphinx(short_audio)\n",
    "    print(\" CMU Sphinx Speech Recognition Output:\\n\", sphinx_text)\n",
    "except sr.UnknownValueError:\n",
    "    sphinx_text = \"N/A\"\n",
    "    print(\" CMU Sphinx could not understand the short segment.\")\n",
    "except sr.RequestError:\n",
    "    sphinx_text = \"N/A\"\n",
    "    print(\" CMU Sphinx API request failed.\")\n",
    "\n",
    "# **OpenAI Whisper (Deep Learning ASR)**\n",
    "print(\" Running Whisper on short segment...\")\n",
    "whisper_model = whisper.load_model(\"base\")\n",
    "\n",
    "# Run Whisper directly on `short_audio.wav`\n",
    "whisper_text = whisper_model.transcribe(\"short_audio.wav\", fp16=False)[\"text\"]\n",
    "print(\" OpenAI Whisper Output:\\n\", whisper_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8debd515-6ebf-485c-9369-f8a44beb4572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7af031eb-1c0e-470e-a65d-f7b8f5f025a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Wav2Vec2 Speech Recognition Output:\n",
      " MANY ANIMALS OF EVEN COMPLEX STRUCTURE WHICH LIVE PARASITICALLY WITHIN OTHE\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "# Load pre-trained Wav2Vec2 model\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
    "\n",
    "# Load and resample audio to 16kHz (required for Wav2Vec2)\n",
    "waveform, sample_rate = torchaudio.load(\"short_audio.wav\")\n",
    "waveform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)(waveform)\n",
    "\n",
    "# Process and predict transcription\n",
    "input_values = processor(waveform.squeeze().numpy(), return_tensors=\"pt\", sampling_rate=16000).input_values\n",
    "logits = model(input_values).logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "wav2vec_text = processor.batch_decode(predicted_ids)[0]\n",
    "\n",
    "print(\" Wav2Vec2 Speech Recognition Output:\\n\", wav2vec_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a26ac-0ea0-40b7-b87c-7e3593245aca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
